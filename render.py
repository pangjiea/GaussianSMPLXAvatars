#
# Copyright (C) 2023, Inria
# GRAPHDECO research group, https://team.inria.fr/graphdeco
# All rights reserved.
#
# This software is free for non-commercial, research and evaluation use 
# under the terms of the LICENSE.md file.
#
# For inquiries contact  george.drettakis@inria.fr
#

import torch
from torch.utils.data import DataLoader
from scene import Scene
import os
from tqdm import tqdm
from os import makedirs
import concurrent.futures
import multiprocessing
from pathlib import Path
from tqdm import tqdm
from PIL import Image
import numpy as np

from gaussian_renderer import render
from utils.general_utils import safe_state
from argparse import ArgumentParser
from arguments import ModelParams, PipelineParams, get_combined_args
from gaussian_renderer import GaussianModel, FlameGaussianModel
from scene.smplx_gaussian_model import SMPLXGaussianModel
from mesh_renderer import NVDiffRenderer


mesh_renderer = NVDiffRenderer()

def write_data(path2data):
    for path, data in path2data.items():
        if not path.parent.exists():
            path.parent.mkdir(parents=True, exist_ok=True)

        if path.suffix in [".png", ".jpg"]:
            data = data.mul(255).add_(0.5).clamp_(0, 255).permute(1, 2, 0).to("cpu", torch.uint8).numpy()
            Image.fromarray(data).save(path)
        elif path.suffix in [".obj"]:
            with open(path, "w") as f:
                f.write(data)
        elif path.suffix in [".txt"]:
            with open(path, "w") as f:
                f.write(data)
        elif path.suffix in [".npz"]:
            np.savez(path, **data)
        else:
            raise NotImplementedError(f"Unknown file type: {path.suffix}")

def render_set(dataset : ModelParams, name, iteration, views, gaussians, pipeline, background, render_mesh):
    if dataset.select_camera_id != -1:
        name = f"{name}_{dataset.select_camera_id}"
    iter_path = Path(dataset.model_path) / name / f"ours_{iteration}"
    render_path = iter_path / "renders"
    gts_path = iter_path / "gt"
    if render_mesh:
        render_mesh_path = iter_path / "renders_mesh"

    makedirs(render_path, exist_ok=True)
    makedirs(gts_path, exist_ok=True)

    views_loader = DataLoader(views, batch_size=None, shuffle=False, num_workers=8)
    max_threads = multiprocessing.cpu_count()
    print('Max threads: ', max_threads)
    worker_args = []
    for idx, view in enumerate(tqdm(views_loader, desc="Rendering progress")):
        if gaussians.binding != None:
            gaussians.select_mesh_by_timestep(view.timestep)
        rendering = render(view, gaussians, pipeline, background)["render"]
        gt = view.original_image[0:3, :, :]
        if render_mesh:
            out_dict = mesh_renderer.render_from_camera(gaussians.verts, gaussians.faces, view)
            rgba_mesh = out_dict['rgba'].squeeze(0).permute(2, 0, 1)  # (C, W, H)
            rgb_mesh = rgba_mesh[:3, :, :]
            alpha_mesh = rgba_mesh[3:, :, :]
            mesh_opacity = 0.5
            rendering_mesh = rgb_mesh * alpha_mesh * mesh_opacity  + gt.to(rgb_mesh) * (alpha_mesh * (1 - mesh_opacity) + (1 - alpha_mesh))

        path2data = {}
        path2data[Path(render_path) / f'{idx:05d}.png'] = rendering
        path2data[Path(gts_path) / f'{idx:05d}.png'] = gt
        if render_mesh:
            path2data[Path(render_mesh_path) / f'{idx:05d}.png'] = rendering_mesh
        worker_args.append([path2data])

        if len(worker_args) == max_threads or idx == len(views_loader)-1:
            with concurrent.futures.ThreadPoolExecutor(max_threads) as executor:
                futures = [executor.submit(write_data, *args) for args in worker_args]
                concurrent.futures.wait(futures)
            worker_args = []
    
    try:
        os.system(f"ffmpeg -y -framerate 25 -f image2 -pattern_type glob -i '{render_path}/*.png' -pix_fmt yuv420p {iter_path}/renders.mp4")
        os.system(f"ffmpeg -y -framerate 25 -f image2 -pattern_type glob -i '{gts_path}/*.png' -pix_fmt yuv420p {iter_path}/gt.mp4")
        if render_mesh:
            os.system(f"ffmpeg -y -framerate 25 -f image2 -pattern_type glob -i '{render_mesh_path}/*.png' -pix_fmt yuv420p {iter_path}/renders_mesh.mp4")
    except Exception as e:
        print(e)

def render_motion_sequence(dataset: ModelParams, iteration: int, pipeline: PipelineParams, motion_npz_path: str,
                          camera_id: int = 0, output_dir: str = "motion_renders", render_mesh: bool = False):
    """
    æ¸²æŸ“SMPLXè¿åŠ¨åºåˆ—

    Args:
        dataset: æ¨¡å‹å‚æ•°
        iteration: è¿­ä»£æ¬¡æ•°
        pipeline: æ¸²æŸ“ç®¡é“å‚æ•°
        motion_npz_path: NPZè¿åŠ¨åºåˆ—æ–‡ä»¶è·¯å¾„
        camera_id: ä½¿ç”¨çš„ç›¸æœºIDï¼ˆé»˜è®¤0ï¼‰
        output_dir: è¾“å‡ºç›®å½•åç§°
        render_mesh: æ˜¯å¦æ¸²æŸ“mesh
    """
    with torch.no_grad():
        print(f"ğŸ¬ å¼€å§‹æ¸²æŸ“è¿åŠ¨åºåˆ—: {motion_npz_path}")

        # åˆ›å»ºSMPLXé«˜æ–¯æ¨¡å‹
        if dataset.bind_to_mesh:
            smplx_flag = os.path.exists(os.path.join(dataset.source_path, "canonical_smplx_param.json"))
            if smplx_flag:
                gaussians = SMPLXGaussianModel(dataset.sh_degree)
            else:
                gaussians = FlameGaussianModel(dataset.sh_degree)
        else:
            print("âŒ é”™è¯¯ï¼šè¿åŠ¨åºåˆ—æ¸²æŸ“éœ€è¦ç»‘å®šåˆ°meshçš„æ¨¡å‹")
            return

        # åŠ è½½åœºæ™¯å’Œæ¨¡å‹
        scene = Scene(dataset, gaussians, load_iteration=iteration, shuffle=False)

        # åŠ è½½è¿åŠ¨åºåˆ—
        print(f"æ­£åœ¨åŠ è½½è¿åŠ¨åºåˆ—: {motion_npz_path}")
        motion_data = np.load(motion_npz_path)
        motion_params = {}
        for k, v in motion_data.items():
            if v.dtype in [np.float32, np.float64]:
                motion_params[k] = torch.from_numpy(v.astype(np.float32)).cuda()
                print(f"  åŠ è½½å‚æ•° {k}: {v.shape} -> {motion_params[k].shape}")
            else:
                print(f"  è·³è¿‡å‚æ•° {k}: dtype={v.dtype}")

        print(f"  æ€»å…±åŠ è½½äº† {len(motion_params)} ä¸ªå‚æ•°")

        # æ£€æµ‹æ¨¡å‹ç±»å‹å¹¶è·å–å¸§æ•°
        if hasattr(gaussians, 'smplx_param') and gaussians.smplx_param is not None:
            model_type = "smplx"
            num_frames = motion_params['expression'].shape[0]
            print(f"âœ“ æ£€æµ‹åˆ°SMPLXæ¨¡å‹ï¼Œè¿åŠ¨åºåˆ—åŒ…å«{num_frames}å¸§")
        elif hasattr(gaussians, 'flame_param') and gaussians.flame_param is not None:
            model_type = "flame"
            num_frames = motion_params['expr'].shape[0]
            print(f"âœ“ æ£€æµ‹åˆ°FLAMEæ¨¡å‹ï¼Œè¿åŠ¨åºåˆ—åŒ…å«{num_frames}å¸§")
        else:
            print("âŒ é”™è¯¯ï¼šæ— æ³•æ£€æµ‹æ¨¡å‹ç±»å‹æˆ–æ¨¡å‹å‚æ•°æœªåŠ è½½")
            return

        # è·å–ç›¸æœº
        train_cameras = scene.getTrainCameras()
        if len(train_cameras) == 0:
            print("âŒ é”™è¯¯ï¼šæ²¡æœ‰æ‰¾åˆ°è®­ç»ƒç›¸æœº")
            return

        # é€‰æ‹©ç›¸æœº
        if camera_id >= len(train_cameras):
            camera_id = 0
            print(f"âš  è­¦å‘Šï¼šç›¸æœºIDè¶…å‡ºèŒƒå›´ï¼Œä½¿ç”¨ç›¸æœº0")

        camera = train_cameras[camera_id]
        print(f"âœ“ ä½¿ç”¨ç›¸æœº {camera_id}")

        # è®¾ç½®è¾“å‡ºè·¯å¾„
        iter_path = Path(dataset.model_path) / output_dir / f"ours_{iteration}"
        render_path = iter_path / "renders"
        if render_mesh:
            render_mesh_path = iter_path / "renders_mesh"
            makedirs(render_mesh_path, exist_ok=True)
        makedirs(render_path, exist_ok=True)

        # è®¾ç½®èƒŒæ™¯
        bg_color = [1,1,1] if dataset.white_background else [0, 0, 0]
        background = torch.tensor(bg_color, dtype=torch.float32, device="cuda")

        print(f"æ­£åœ¨æ¸²æŸ“{num_frames}å¸§...")

        # æ¸²æŸ“æ¯ä¸€å¸§
        for timestep in tqdm(range(num_frames), desc="æ¸²æŸ“è¿›åº¦"):
            try:
                # åº”ç”¨è¿åŠ¨å‚æ•°åˆ°æ¨¡å‹
                if model_type == "smplx":
                    # ç›´æ¥æ„å»ºå½“å‰å¸§çš„å‚æ•°å­—å…¸ï¼Œä¸ä¾èµ–è®­ç»ƒåå‚æ•°çš„å¸§æ•°
                    frame_param = {}

                    # ä»è®­ç»ƒåå‚æ•°ä¸­è·å–é™æ€å‚æ•°
                    if gaussians.smplx_param is not None:
                        for key, value in gaussians.smplx_param.items():
                            if key == 'betas':
                                # betasæ˜¯é™æ€çš„ï¼Œç›´æ¥ä½¿ç”¨è®­ç»ƒåçš„å€¼
                                frame_param[key] = value
                            # å…¶ä»–å‚æ•°å…ˆä¸å¤„ç†ï¼Œç­‰NPZè¦†ç›–

                    # ç”¨NPZä¸­çš„åŠ¨æ€å‚æ•°æ„å»ºå½“å‰å¸§å‚æ•°
                    for key, value in motion_params.items():
                        if key == 'betas':
                            # å¦‚æœNPZä¸­æœ‰betasä½†è®­ç»ƒåå‚æ•°ä¸­ä¹Ÿæœ‰ï¼Œä¼˜å…ˆä½¿ç”¨è®­ç»ƒåçš„
                            if 'betas' not in frame_param:
                                frame_param[key] = value
                        else:
                            # åŠ¨æ€å‚æ•°ï¼šä½¿ç”¨NPZä¸­å½“å‰æ—¶é—´æ­¥çš„å€¼
                            if len(value.shape) > 1:
                                frame_param[key] = value[[timestep]]  # ä¿æŒbatchç»´åº¦
                            else:
                                frame_param[key] = value  # é™æ€å‚æ•°

                    # ç¡®ä¿æ‰€æœ‰å¿…è¦çš„å‚æ•°éƒ½å­˜åœ¨
                    if 'betas' not in frame_param:
                        # å¦‚æœæ²¡æœ‰betasï¼Œåˆ›å»ºé»˜è®¤å€¼
                        frame_param['betas'] = torch.zeros(100, device='cuda')

                    # ä½¿ç”¨SMPLXå‰å‘ä¼ æ’­
                    verts, verts_cano = gaussians._smplx_forward(frame_param)
                    gaussians.update_mesh_properties(verts, verts_cano)

                elif model_type == "flame":
                    # ç›´æ¥æ„å»ºå½“å‰å¸§çš„FLAMEå‚æ•°
                    frame_param = {}

                    # ä»è®­ç»ƒåå‚æ•°ä¸­è·å–é™æ€å‚æ•°
                    if gaussians.flame_param is not None:
                        for key, value in gaussians.flame_param.items():
                            if key in ['shape', 'static_offset']:
                                # é™æ€å‚æ•°ï¼Œç›´æ¥ä½¿ç”¨è®­ç»ƒåçš„å€¼
                                frame_param[key] = value

                    # ç”¨NPZä¸­çš„åŠ¨æ€å‚æ•°æ„å»ºå½“å‰å¸§å‚æ•°
                    for key, value in motion_params.items():
                        if key in ['shape', 'static_offset']:
                            # å¦‚æœNPZä¸­æœ‰é™æ€å‚æ•°ä½†è®­ç»ƒåå‚æ•°ä¸­ä¹Ÿæœ‰ï¼Œä¼˜å…ˆä½¿ç”¨è®­ç»ƒåçš„
                            if key not in frame_param:
                                frame_param[key] = value
                        else:
                            # åŠ¨æ€å‚æ•°ï¼šä½¿ç”¨NPZä¸­å½“å‰æ—¶é—´æ­¥çš„å€¼
                            if len(value.shape) > 1:
                                frame_param[key] = value[[timestep]]  # ä¿æŒbatchç»´åº¦
                            else:
                                frame_param[key] = value  # é™æ€å‚æ•°

                    # ä½¿ç”¨FLAMEæ¨¡å‹çš„å‰å‘ä¼ æ’­
                    verts, verts_cano = gaussians.flame_model(
                        frame_param['shape'][None, ...],
                        frame_param['expr'],
                        frame_param['rotation'],
                        frame_param['neck_pose'],
                        frame_param['jaw_pose'],
                        frame_param['eyes_pose'],
                        frame_param['translation'],
                        zero_centered_at_root_node=False,
                        return_landmarks=False,
                        return_verts_cano=True,
                        static_offset=frame_param['static_offset'],
                        dynamic_offset=frame_param['dynamic_offset'],
                    )
                    gaussians.update_mesh_properties(verts, verts_cano)

                # æ¸²æŸ“å½“å‰å¸§
                rendering = render(camera, gaussians, pipeline, background)["render"]

                # ä¿å­˜æ¸²æŸ“ç»“æœ
                render_image = rendering.mul(255).add_(0.5).clamp_(0, 255).permute(1, 2, 0).to("cpu", torch.uint8).numpy()
                Image.fromarray(render_image).save(render_path / f"frame_{timestep:06d}.png")

                # å¦‚æœéœ€è¦ï¼Œæ¸²æŸ“mesh
                if render_mesh and hasattr(gaussians, 'verts') and hasattr(gaussians, 'faces'):
                    out_dict = mesh_renderer.render_from_camera(gaussians.verts, gaussians.faces, camera)
                    rgba_mesh = out_dict['rgba'].squeeze(0).permute(2, 0, 1)
                    rgb_mesh = rgba_mesh[:3, :, :]
                    alpha_mesh = rgba_mesh[3:, :, :]
                    mesh_opacity = 0.5

                    # åˆ›å»ºä¸€ä¸ªé»‘è‰²èƒŒæ™¯ç”¨äºmeshæ¸²æŸ“
                    black_bg = torch.zeros_like(rendering)
                    rendering_mesh = rgb_mesh * alpha_mesh * mesh_opacity + black_bg * (alpha_mesh * (1 - mesh_opacity) + (1 - alpha_mesh))

                    mesh_image = rendering_mesh.mul(255).add_(0.5).clamp_(0, 255).permute(1, 2, 0).to("cpu", torch.uint8).numpy()
                    Image.fromarray(mesh_image).save(render_mesh_path / f"frame_{timestep:06d}.png")

            except Exception as e:
                print(f"âš  è­¦å‘Šï¼šæ¸²æŸ“ç¬¬{timestep}å¸§æ—¶å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()
                continue

        # ç”Ÿæˆè§†é¢‘
        try:
            print("æ­£åœ¨ç”Ÿæˆè§†é¢‘...")
            os.system(f"ffmpeg -y -framerate 25 -f image2 -pattern_type glob -i '{render_path}/*.png' -pix_fmt yuv420p {iter_path}/motion_sequence.mp4")
            if render_mesh:
                os.system(f"ffmpeg -y -framerate 25 -f image2 -pattern_type glob -i '{render_mesh_path}/*.png' -pix_fmt yuv420p {iter_path}/motion_sequence_mesh.mp4")
            print(f"âœ… è§†é¢‘å·²ä¿å­˜åˆ°: {iter_path}/motion_sequence.mp4")
        except Exception as e:
            print(f"âš  è­¦å‘Šï¼šç”Ÿæˆè§†é¢‘æ—¶å‡ºé”™: {e}")

        print(f"âœ… è¿åŠ¨åºåˆ—æ¸²æŸ“å®Œæˆï¼è¾“å‡ºç›®å½•: {iter_path}")

def render_sets(dataset : ModelParams, iteration : int, pipeline : PipelineParams, skip_train : bool, skip_val : bool, skip_test : bool, render_mesh: bool):
    with torch.no_grad():
        if dataset.bind_to_mesh:
            smplx_flag = os.path.exists(os.path.join(dataset.source_path, "canonical_smplx_param.json"))
            if smplx_flag:
                gaussians = SMPLXGaussianModel(dataset.sh_degree)
            else:
                gaussians = FlameGaussianModel(dataset.sh_degree)
        else:
            gaussians = GaussianModel(dataset.sh_degree)
        scene = Scene(dataset, gaussians, load_iteration=iteration, shuffle=False)

        bg_color = [1,1,1] if dataset.white_background else [0, 0, 0]
        background = torch.tensor(bg_color, dtype=torch.float32, device="cuda")

        if dataset.target_path != "":
             name = os.path.basename(os.path.normpath(dataset.target_path))
             # when loading from a target path, test cameras are merged into the train cameras
             render_set(dataset, f'{name}', scene.loaded_iter, scene.getTrainCameras(), gaussians, pipeline, background, render_mesh)
        else:
            if not skip_train:
                render_set(dataset, "train", scene.loaded_iter, scene.getTrainCameras(), gaussians, pipeline, background, render_mesh)

            if not skip_val:
                render_set(dataset, "val", scene.loaded_iter, scene.getValCameras(), gaussians, pipeline, background, render_mesh)

            if not skip_test:
                render_set(dataset, "test", scene.loaded_iter, scene.getTestCameras(), gaussians, pipeline, background, render_mesh)

if __name__ == "__main__":
    # Set up command line argument parser
    parser = ArgumentParser(description="Testing script parameters")
    model = ModelParams(parser, sentinel=True)
    pipeline = PipelineParams(parser)
    parser.add_argument("--iteration", default=-5000, type=int)
    parser.add_argument("--skip_train", action="store_true")
    parser.add_argument("--skip_val", action="store_true")
    parser.add_argument("--skip_test", action="store_true")
    parser.add_argument("--quiet", action="store_true")
    parser.add_argument("--render_mesh", action="store_true")

    # æ–°å¢ï¼šè¿åŠ¨åºåˆ—æ¸²æŸ“å‚æ•°
    parser.add_argument("--motion_npz", type=str, help="NPZè¿åŠ¨åºåˆ—æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºæ¸²æŸ“è¿åŠ¨åºåˆ—ï¼‰")
    parser.add_argument("--camera_id", type=int, default=0, help="ç”¨äºæ¸²æŸ“çš„ç›¸æœºIDï¼ˆé»˜è®¤0ï¼‰")
    parser.add_argument("--output_dir", type=str, default="motion_renders", help="è¿åŠ¨åºåˆ—æ¸²æŸ“è¾“å‡ºç›®å½•åç§°")

    args = get_combined_args(parser)
    print("Rendering " + args.model_path)

    # Initialize system state (RNG)
    safe_state(args.quiet)

    # æ£€æŸ¥æ˜¯å¦æ˜¯è¿åŠ¨åºåˆ—æ¸²æŸ“æ¨¡å¼
    if args.motion_npz:
        print("ğŸ¬ è¿åŠ¨åºåˆ—æ¸²æŸ“æ¨¡å¼")
        if not os.path.exists(args.motion_npz):
            print(f"âŒ é”™è¯¯ï¼šè¿åŠ¨åºåˆ—æ–‡ä»¶ä¸å­˜åœ¨: {args.motion_npz}")
            exit(1)

        render_motion_sequence(
            model.extract(args),
            args.iteration,
            pipeline.extract(args),
            args.motion_npz,
            args.camera_id,
            args.output_dir,
            args.render_mesh
        )
    else:
        print("ğŸ“· æ ‡å‡†æ¸²æŸ“æ¨¡å¼")
        render_sets(model.extract(args), args.iteration, pipeline.extract(args), args.skip_train, args.skip_val, args.skip_test, args.render_mesh)