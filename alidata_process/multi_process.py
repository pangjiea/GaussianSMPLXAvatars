# alidata_process/process.py
# ============================
import json
import os
import shutil
from pathlib import Path
import numpy as np
import math
from tqdm import tqdm
from copy import deepcopy
import random
import cv2  # ç”¨äºå¤„ç†Rodrigueså‘é‡å’Œå›¾åƒå»ç•¸å˜
from concurrent.futures import ThreadPoolExecutor, as_completed

# --- é…ç½®åŒºåŸŸ ---
alidata_path = Path("/home/hello/data")
subject_name = "SC_01"

MASK_BASE_DIR = Path("/home/hello/remote/server2/data1/sapiens_processing/final_head_segments_multigpu/raw_videos/masks")
IMAGE_BASE_DIR = Path("/home/hello/remote/server2/data1/sapiens_processing/final_head_segments_multigpu/raw_videos/masked_images")  # åŸå§‹å›¾åƒç›®å½•
UNDISTORTED_IMAGE_DIR = Path("/home/hello/remote/server2/data1/sapiens_processing/alidata_process/undistorted_images") / subject_name
SMPLX_FITTING_DIR = alidata_path / subject_name / "smplx_fitting"
CALIBRATION_FILE = alidata_path / subject_name / "calibration.json"
OUTPUT_DATASET_DIR = Path("/home/hello/data/SC_01/export")

NUM_FRAMES = 1280  # æ€»å¸§æ•°
USED_CAMERA_ID_STR_LIST = ["019","028","001","046","003","004","005","009","010","017","022","031","032","041"]  # ä½¿ç”¨çš„ç›¸æœºIDåˆ—è¡¨
TEST_CAMERA_ID_STR_LIST = []  # æµ‹è¯•é›†ç›¸æœºID
TEST_FRAMES_RATIO = 0.1
TRAIN_VAL_SUBJECT_SEED = "SC_01"

# å…¨å±€å˜é‡ï¼Œç”¨äºå¹¶è¡Œè®¿é—®ï¼ˆé‡å‘½åä»¥åæ˜ OpenCVåæ ‡ç³»ï¼‰
all_camera_params_opencv = {}
cam_id_str_to_int_idx = {}

# --- è¾…åŠ©å‡½æ•° ---
def ensure_dir(path: Path):
    path.mkdir(parents=True, exist_ok=True)


def write_json_to_file(data, filepath: Path, indent=4):
    print(f"æ­£åœ¨å†™å…¥ JSON åˆ°: {filepath}")
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=indent, ensure_ascii=False)


def load_smplx_params(json_path: Path):
    with open(json_path, 'r') as f:
        return json.load(f)


def save_smplx_params(params, json_path: Path):
    ensure_dir(json_path.parent)
    for key, value in params.items():
        if isinstance(value, np.ndarray):
            params[key] = value.tolist()
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(params, f, indent=4)


def create_canonical_smplx_params(first_frame_smplx_path: Path, output_path: Path):
    print(f"æ­£åœ¨ä» {first_frame_smplx_path} åˆ›å»ºæ ‡å‡†SMPL-Xå‚æ•° (canonical_smplx_param.json)")
    params = load_smplx_params(first_frame_smplx_path)
    canonical_params = {}
    # betas or shape
    if 'betas' in params:
        canonical_params['betas'] = params['betas']
    elif 'shape' in params:
        canonical_params['betas'] = params['shape']
    else:
        print("è­¦å‘Š: æœªæ‰¾åˆ° 'betas' æˆ– 'shape'ï¼Œä½¿ç”¨é›¶å‘é‡ã€‚")
        canonical_params['betas'] = np.zeros(100).tolist()
    # å…¶ä»–å‚æ•°ç½®é›¶
    param_zeros_configs = {
        'global_orient': 3, 'body_pose': 63, 'jaw_pose': 3, 'leye_pose': 3,
        'reye_pose': 3, 'expression': 50, 'transl': 3,
        'left_hand_pose': 45, 'right_hand_pose': 45,
        'Rh': 3, 'Th': 3
    }
    for key, default_size in param_zeros_configs.items():
        if key in params:
            arr = np.array(params[key])
            # å¦‚æœåµŒå¥—åˆ—è¡¨
            if arr.ndim > 1:
                canonical_params[key] = [np.zeros_like(sub).tolist() for sub in arr]
            else:
                canonical_params[key] = np.zeros_like(arr).tolist()
        else:
            canonical_params[key] = np.zeros(default_size).tolist()
            print(f"ä¿¡æ¯: å‚æ•° '{key}' æœªåœ¨æºæ–‡ä»¶ä¸­æ‰¾åˆ°ï¼Œå·²æ·»åŠ é›¶å€¼ã€‚")
    canonical_params['gender'] = params.get('gender', 'neutral')
    save_smplx_params(canonical_params, output_path)
    print(f"æ ‡å‡†SMPL-Xå‚æ•°å·²ä¿å­˜åˆ°: {output_path}")
    return canonical_params


def process_calibration_data(calib_file: Path, specified_camera_ids: list = None):
    data = json.load(open(calib_file, 'r'))
    cameras = data.get('cameras', {})
    poses = data.get('camera_poses', {})
    
    if specified_camera_ids:
        ids = [cid for cid in specified_camera_ids if cid in cameras and cid in poses]
        missing = set(specified_camera_ids) - set(ids)
        if missing:
            print(f"è­¦å‘Š: ç›¸æœºID æœªæ‰¾åˆ°: {missing}")
    else:
        ids = [cid for cid in cameras if cid in poses]
    
    if not ids:
        raise ValueError("æ²¡æœ‰å¯ç”¨çš„ç›¸æœºæ•°æ®")
    
    out = {}
    for cid in tqdm(ids, desc="å¤„ç†ç›¸æœºæ ‡å®š"):
        intr = cameras[cid]
        w, h = intr['image_size']
        K = np.array(intr['K'])
        dist = np.array(intr.get('dist', np.zeros(5))).flatten()
        
        fx, fy = K[0,0], K[1,1]
        angle_x = 2 * math.atan(w / (2 * fx))
        angle_y = 2 * math.atan(h / (2 * fy))
        
        p = poses[cid]
        R = np.array(p['R'])
        T = np.array(p['T']).flatten()
        w2c = np.eye(4)
        w2c[:3,:3] = R
        w2c[:3,3] = T
        c2w = np.linalg.inv(w2c)   
        c2w_final = c2w

        cx, cy = K[0,2], K[1,2]
        out[cid] = {
            'id': int(cid),
            'width': w,
            'height': h,
            'camera_angle_x': angle_x,
            'camera_angle_y': angle_y,
            'fl_x': fx,
            'fl_y': fy,
            'cx': cx,
            'cy': cy,
            'transform_matrix': c2w_final.tolist(),
            
            # åŸå§‹å‚æ•°ï¼ˆç”¨äºå»ç•¸å˜å¤„ç†ï¼‰
            'original_K_cv': K.tolist(),
            'original_dist_cv': dist.tolist(),
            
            # å»ç•¸å˜åçš„å‚æ•°ï¼ˆç”¨äºåç»­æ¸²æŸ“ï¼‰
            'undistorted_K_cv': K.tolist(),  # KçŸ©é˜µä¿æŒä¸å˜
            'undistorted_dist_cv': [0.0, 0.0, 0.0, 0.0, 0.0],  # ç•¸å˜ç³»æ•°ç½®é›¶
            
            # æ ‡è®°å›¾åƒå·²å»ç•¸å˜å’Œä¸»ç‚¹ä¿¡æ¯
            'image_undistorted': True,
        }
    
    print(f"âœ… æˆåŠŸå¤„ç† {len(out)} ä¸ªç›¸æœºï¼Œä½¿ç”¨OpenCVåæ ‡ç³»")
    return out


def process_single_frame_cam(frame_idx, cam_id_str):
    global all_camera_params_opencv, cam_id_str_to_int_idx
    
    # SMPL-X å‚æ•°
    src = SMPLX_FITTING_DIR/f"{frame_idx:06d}.json"
    if not src.exists():
        return None
    rel = Path('smplx_param')/src.name
    shutil.copyfile(str(src), str(OUTPUT_DATASET_DIR/rel))
    
    # ç¡®ä¿æ¯ä¸ªç›¸æœºä½¿ç”¨æ­£ç¡®çš„å‚æ•°
    if cam_id_str not in all_camera_params_opencv:
        print(f"é”™è¯¯: ç›¸æœºID {cam_id_str} ä¸å­˜åœ¨äºç›¸æœºå‚æ•°ä¸­")
        return None
    
    cam = all_camera_params_opencv[cam_id_str]
    
    # ä½¿ç”¨åŸå§‹å‚æ•°è¿›è¡Œå»ç•¸å˜
    K_original = np.array(cam['original_K_cv'])
    dist_original = np.array(cam['original_dist_cv'])
    
    stem = f"{frame_idx:06d}_{cam_id_str}"
    img_p = IMAGE_BASE_DIR/f"{stem}.png"
    if not img_p.exists(): 
        img_p = IMAGE_BASE_DIR/f"{stem}.jpg"
    mask_p = MASK_BASE_DIR/f"{stem}.png"
    
    if not img_p.exists() or not mask_p.exists(): 
        return None
    
    img = cv2.imread(str(img_p))
    mask = cv2.imread(str(mask_p), cv2.IMREAD_GRAYSCALE)
    
    if img is None or mask is None: 
        return None
    
    # å»ç•¸å˜å¤„ç†
    img_undistorted = cv2.undistort(img, K_original, dist_original, None, K_original)
    
    # å¯é€‰ï¼šä¹Ÿå¯¹maskè¿›è¡Œå»ç•¸å˜ï¼ˆå¦‚æœmaskæ˜¯åœ¨åŸå§‹å›¾åƒä¸Šç”Ÿæˆçš„ï¼‰
    mask_undistorted = cv2.undistort(mask, K_original, dist_original, None, K_original)
    
    idx = cam_id_str_to_int_idx[cam_id_str]
    name = f"{frame_idx:06d}_{idx:02d}.png"

    # ä¿å­˜å»ç•¸å˜åçš„å›¾åƒå’Œmaskåˆ°è¾“å‡ºæ•°æ®é›†ç›®å½•
    cv2.imwrite(str(OUTPUT_DATASET_DIR/'images'/name), img_undistorted)
    cv2.imwrite(str(OUTPUT_DATASET_DIR/'masks_images'/name), mask_undistorted)
    
    return {
        "timestep_index": frame_idx,
        "timestep_index_original": frame_idx,
        "camera_index": idx,

        "cx": cam['cx'],
        "cy": cam['cy'],
        "fl_x": cam['fl_x'],
        "fl_y": cam['fl_y'],
        "h": cam['height'],
        "w": cam['width'],
        "camera_angle_x": cam['camera_angle_x'],
        "camera_angle_y": cam['camera_angle_y'],
        
        "transform_matrix": cam['transform_matrix'],

        "file_path": str(Path('images')/name),
        "fg_mask_path": str(Path('masks_images')/name),
        "smplx_param_path": str(rel),
    }


def setup_directories():
    """åˆ›å»ºæ‰€æœ‰å¿…è¦çš„è¾“å‡ºç›®å½•ã€‚"""
    print("ğŸ“‚ åˆ›å»ºè¾“å‡ºç›®å½•...")
    for p in [OUTPUT_DATASET_DIR, OUTPUT_DATASET_DIR/'images', OUTPUT_DATASET_DIR/'masks_images', OUTPUT_DATASET_DIR/'smplx_param', UNDISTORTED_IMAGE_DIR]:
        ensure_dir(p)
    print("âœ… ç›®å½•åˆ›å»ºå®Œæˆã€‚")

def load_and_process_calibration():
    """åŠ è½½å¹¶å¤„ç†ç›¸æœºæ ‡å®šæ•°æ®ã€‚"""
    try:
        camera_params = process_calibration_data(CALIBRATION_FILE, USED_CAMERA_ID_STR_LIST)
        sorted_ids = sorted(camera_params.keys(), key=int)
        cam_id_map = {cid: i for i, cid in enumerate(sorted_ids)}
        return camera_params, cam_id_map, sorted_ids
    except Exception as e:
        print(f"âŒ æ ‡å®šå¤„ç†å¤±è´¥: {e}")
        return None, None, None

def create_canonical_smplx_parameters():
    """åˆ›å»ºæ ‡å‡†SMPL-Xå‚æ•°ã€‚"""
    first_frame_smplx_path = SMPLX_FITTING_DIR / '000009.json'
    if not first_frame_smplx_path.exists():
        print("âŒ ç¼ºå°‘ç¬¬ä¸€å¸§SMPL-Xå‚æ•°æ–‡ä»¶: 000009.json")
        return False
    create_canonical_smplx_params(first_frame_smplx_path, OUTPUT_DATASET_DIR / 'canonical_smplx_param.json')
    return True

def process_all_frames_and_cameras(camera_params, cam_id_map, sorted_camera_ids):
    """å¹¶è¡Œå¤„ç†æ‰€æœ‰å¸§å’Œç›¸æœºï¼ŒåŒ…æ‹¬SMPL-Xå‚æ•°å¤åˆ¶ã€å›¾åƒå»ç•¸å˜å’Œæ©ç å¤„ç†ã€‚"""
    global all_camera_params_opencv, cam_id_str_to_int_idx
    all_camera_params_opencv = camera_params
    cam_id_str_to_int_idx = cam_id_map

    # è®¡ç®—è·³è·ƒè¯»å–çš„å¸§æ•°å’Œæ­¥é•¿
    total_frames = NUM_FRAMES
    num_frames_to_read = max(1, int(total_frames * 0.01))  # å‡åˆ†è¯»å–å…¶ä¸­çš„20%
    step = max(1, int(total_frames / num_frames_to_read))

    print(f"æ€»å¸§æ•°: {total_frames}, å°†è·³è·ƒè¯»å– {num_frames_to_read} å¸§ï¼Œæ­¥é•¿ä¸º {step}")

    tasks = [(f, c) for f in range(0, total_frames, step) if (SMPLX_FITTING_DIR / f"{f:06d}.json").exists() for c in sorted_camera_ids]
    frames_all = []
    with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:
        futures = {executor.submit(process_single_frame_cam, f, c): (f, c) for f, c in tasks}
        for future in tqdm(as_completed(futures), total=len(futures), desc="å¹¶è¡Œå¯¼å‡ºå¸§æ•°æ®"):
            result = future.result()
            if result:
                frames_all.append(result)
    return frames_all

def generate_transforms_metadata(frames_data, camera_params, sorted_camera_ids):
    """ç”Ÿæˆtransforms.jsonæ–‡ä»¶çš„å…ƒæ•°æ®ã€‚"""
    meta = {
        'camera_angle_x': 0, 'camera_angle_y': 0, 'fl_x': 0, 'fl_y': 0, 'cx': 0, 'cy': 0, 'w': 0, 'h': 0,
        'frames': [],'applied_transform': np.eye(4).tolist(),
        'k1': 0, 'k2': 0, 'p1': 0, 'p2': 0, 'k3': 0
    }

    if sorted_camera_ids:
        first_cam_id = sorted_camera_ids[0]
        first_cam_data = camera_params[first_cam_id]
        meta.update({
            'camera_angle_x': first_cam_data['camera_angle_x'],
            'camera_angle_y': first_cam_data['camera_angle_y'],
            'fl_x': first_cam_data['fl_x'],
            'fl_y': first_cam_data['fl_y'],
            'cx': first_cam_data['cx'],
            'cy': first_cam_data['cy'],
            'w': first_cam_data['width'],
            'h': first_cam_data['height'],
            'k1': 0.0, 'k2': 0.0, 'k3': 0.0,
            'p1': 0.0, 'p2': 0.0,
            'images_undistorted': True,
            'distortion_model': 'none',
        })
    else:
        print("è­¦å‘Šï¼šæ²¡æœ‰å¯ç”¨çš„ç›¸æœºå‚æ•°æ¥åˆå§‹åŒ–metaå­—å…¸ã€‚")
        
    meta['frames'] = frames_data
    if frames_data:
        meta['timestep_indices'] = sorted(list(set(f['timestep_index'] for f in frames_data)))
        meta['camera_indices'] = sorted(list(set(f['camera_index'] for f in frames_data)))
    else:
        meta['timestep_indices'] = []
        meta['camera_indices'] = []
    
    write_json_to_file(meta, OUTPUT_DATASET_DIR / 'transforms.json')
    return meta

def split_dataset_and_save_metadata(frames_data, base_meta, cam_id_map):
    """åˆ’åˆ†è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†å¹¶ä¿å­˜ç›¸åº”çš„transforms_*.jsonæ–‡ä»¶ã€‚"""
    print("ğŸ“Š åˆ’åˆ† train/val/test æ•°æ®é›†...")

    test_camera_int_ids = {cam_id_map[c] for c in TEST_CAMERA_ID_STR_LIST if c in cam_id_map}
    test_set = [f for f in frames_data if f['camera_index'] in test_camera_int_ids]
    
    train_val_set = [f for f in frames_data if f not in test_set]
    
    train_val_timesteps = sorted({f['timestep_index'] for f in train_val_set})
    num_val_frames = int(len(train_val_timesteps) * TEST_FRAMES_RATIO) or 1
    
    rng = random.Random(TRAIN_VAL_SUBJECT_SEED)
    rng.shuffle(train_val_timesteps)
    
    val_timesteps = set(train_val_timesteps[:num_val_frames])
    train_timesteps = set(train_val_timesteps[num_val_frames:])
    
    train_set = [f for f in train_val_set if f['timestep_index'] in train_timesteps]
    val_set = [f for f in train_val_set if f['timestep_index'] in val_timesteps]

    def save_split_metadata(name, data_subset):
        split_meta = deepcopy(base_meta)
        split_meta['frames'] = data_subset
        split_meta['timestep_indices'] = sorted(list(set(f['timestep_index'] for f in data_subset)))
        split_meta['camera_indices'] = sorted(list(set(f['camera_index'] for f in data_subset)))
        write_json_to_file(split_meta, OUTPUT_DATASET_DIR / f'transforms_{name}.json')

    save_split_metadata('train', train_set)
    save_split_metadata('val', val_set)
    save_split_metadata('test', test_set)
    
    print(f"âœ… æ•°æ®é›†åˆ’åˆ†å®Œæˆ: è®­ç»ƒé›†={len(train_set)}, éªŒè¯é›†={len(val_set)}, æµ‹è¯•é›†={len(test_set)}")

def main():
    setup_directories()

    camera_params, cam_id_map, sorted_camera_ids = load_and_process_calibration()
    if camera_params is None:
        return

    if not create_canonical_smplx_parameters():
        return

    frames_data = process_all_frames_and_cameras(camera_params, cam_id_map, sorted_camera_ids)
    
    base_meta = generate_transforms_metadata(frames_data, camera_params, sorted_camera_ids)
    
    split_dataset_and_save_metadata(frames_data, base_meta, cam_id_map)

if __name__ == '__main__':
    main()
